{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import needed packages\n",
    "import multiprocessing as mp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import class_3_model as cm\n",
    "import time\n",
    "\n",
    "\n",
    "# read in data for random n\n",
    "df_random_n = pd.read_csv(\"class_3_random_n.csv\")\n",
    "# set the number of values to iterate over \n",
    "n_iter = 20\n",
    "n_iter = min(n_iter, len(df_random_n))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.7711920738220215"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# demonstration run using a large n\n",
    "t0 = time.time()\n",
    "n = 5000\n",
    "rv = cm.log_sum_binomial(n, None)\n",
    "time.time() - t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t1 iterations complete\n",
      "\t5 iterations complete\n",
      "\t9 iterations complete\n",
      "\t13 iterations complete\n",
      "\t17 iterations complete\n",
      "Serial run complete in 84.57079315185547 seconds.\n"
     ]
    }
   ],
   "source": [
    "###########################\n",
    "#    SERIAL 'FOR' LOOP    #\n",
    "###########################\n",
    "\n",
    "# initialize output values\n",
    "vec_logsums = [0 for x in range(len(df_random_n))]\n",
    "\n",
    "# set timer baseline\n",
    "t0_serial = time.time()\n",
    "\n",
    "# simple loop over\n",
    "for i in range(n_iter):\n",
    "    # important for this model to conver to int based on numerical issues\n",
    "    vec_logsums[i] = cm.log_sum_binomial(int(df_random_n[\"random_n\"].iloc[i]), int(df_random_n[\"random_n_id\"].iloc[i]))\n",
    "    \n",
    "    if i%round(n_iter/5) == 0:\n",
    "        print(\"\\t%s iterations complete\"%(i + 1))\n",
    "\n",
    "t1_serial = time.time()\n",
    "t_elapse_serial = t1_serial - t0_serial\n",
    "\n",
    "print(\"Serial run complete in %s seconds.\"%t_elapse_serial)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Asynchronous parallelization across 12 cores reduced computational time by 75.81%.\n"
     ]
    }
   ],
   "source": [
    "###############################\n",
    "#    ASYNCHRONOUS PARALLEL    #\n",
    "###############################\n",
    "\n",
    "t0_par_async = time.time()\n",
    "\n",
    "#\n",
    "# SOLUTION TO GET APPLY_ASYNC TO WORK WITH JUPYTER LAB: FUNCTION HAS TO BE PLACED IN MODULE AND IMPORTED: https://stackoverflow.com/questions/47313732/jupyter-notebook-never-finishes-processing-using-multiprocessing-python-3\n",
    "# https://towardsdatascience.com/asynchronous-parallel-programming-in-python-with-multiprocessing-a3fc882b4023\n",
    "#\n",
    "\n",
    "# initialize output vector/array (pre-allocate memory)\n",
    "vec_logsums_par_async = []\n",
    "\n",
    "# set up dummy functions to get results\n",
    "def get_result(result):\n",
    "    \n",
    "    global vec_logsums_par_async\n",
    "    \n",
    "    rand_id = result[0]\n",
    "    val = result[1]\n",
    "    \n",
    "    # update\n",
    "    vec_logsums_par_async.append(result)\n",
    "    #vec_randids_par_async.append(rand_id)\n",
    "\n",
    "# check to ensure current module is \"__main__\"; this is necessary in scripts that use multiprocessing. Without it, the processing framework will run the entirety of the original script in parallel\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # start the MP pool for asynchronous parallelization\n",
    "    pool = mp.Pool(mp.cpu_count())\n",
    "\n",
    "    # apply the function; note: if the function only takes one argument (e.g., f(x)), make sure the args is args = (x, ) - that extra comma is important\n",
    "    for i in range(n_iter):\n",
    "        pool.apply_async(\n",
    "            # target function\n",
    "            cm.log_sum_binomial,\n",
    "            # function arguments \n",
    "            args = (int(df_random_n[\"random_n\"].iloc[i]), int(df_random_n[\"random_n_id\"].iloc[i])),\n",
    "            callback = get_result\n",
    "        )\n",
    "        \n",
    "        # \n",
    "        # pseudocode attempt at describing this function:\n",
    "        # for i in 0:(n_iter - 1):\n",
    "        #  assign task i to Pool\n",
    "        #  use cm.log_sum_binomial with arguments (int(df_random_n[\"random_n\"].iloc[i]), int(df_random_n[\"random_n_id\"].iloc[i]))\n",
    "        #  when task i finishes, apply get_results to the outpue\n",
    "        #\n",
    "\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    t1_par_async = time.time()\n",
    "\n",
    "    # \n",
    "    t_elapse_par_async = t1_par_async - t0_par_async\n",
    "\n",
    "# print the reduction in time\n",
    "print(\"Asynchronous parallelization across %s cores reduced computational time by %s%s.\"%(mp.cpu_count(), round(100*(1 - t_elapse_par_async/t_elapse_serial), 2), \"%\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4, 2796.848873559379),\n",
       " (11, 2842.5965874763356),\n",
       " (9, 2874.481357782093),\n",
       " (2, 2959.0453138104062),\n",
       " (12, 3044.9955641998395),\n",
       " (5, 3055.3927719082385),\n",
       " (6, 3058.858507811038),\n",
       " (8, 3180.852411589589),\n",
       " (7, 3223.8275367843053),\n",
       " (3, 3259.1780429928626),\n",
       " (1, 3332.651644132217),\n",
       " (10, 3366.615855979654),\n",
       " (13, 2909.83186399065),\n",
       " (15, 2974.987698963285),\n",
       " (19, 2891.1168901155315),\n",
       " (20, 2775.361310962021),\n",
       " (17, 3015.1902354357617),\n",
       " (14, 3284.8244886735806),\n",
       " (18, 3176.693528506229),\n",
       " (16, 3415.1361586188505)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine results from the pool, which gives us tuples with the random_n_id + the output value associated with it\n",
    "vec_logsums_par_async\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 2796.848873559379)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##  verify the values shown above (interactive)\n",
    "# set the random id to check\n",
    "rand_id_check = 4\n",
    "# get the applicable data row\n",
    "row = df_random_n[df_random_n[\"random_n_id\"] == rand_id_check]\n",
    "#\n",
    "cm.log_sum_binomial(int(row[\"random_n\"]), int(row[\"random_n_id\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synchronous parallelization across 12 cores reduced computational time by 78.79%.\n"
     ]
    }
   ],
   "source": [
    "##############################\n",
    "#    SYNCHRONOUS PARALLEL    #\n",
    "##############################\n",
    "\n",
    "#\n",
    "# check to ensure current module is \"__main__\"; this is necessary in scripts that use multiprocessing. Without it, the processing framework will run the entirety of the original script in parallel\n",
    "# more on this is available at: https://docs.python.org/3/library/multiprocessing.html#multiprocessing-programming\n",
    "#\n",
    "# this approach is similar to running it in R\n",
    "#\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # start the MP pool for asynchronous parallelization\n",
    "    n_cores = mp.cpu_count()\n",
    "\n",
    "    # copy the range\n",
    "    list_task = list(range(n_iter))\n",
    "    \n",
    "    # set the outer return dictionary\n",
    "    return_values = {}\n",
    "    \n",
    "    # set kill timer\n",
    "    t0_par_sync = time.time()\n",
    "    # upper threshold\n",
    "    t_max = len(list_task)*20\n",
    "    \n",
    "    # set\n",
    "    while ((len(list_task) > 0) & (time.time() - t0_par_sync < t_max)):\n",
    "        \n",
    "        # initialize the manager\n",
    "        man = mp.Manager()\n",
    "        return_dict = man.dict()\n",
    "        \n",
    "        # initialize the list of processes\n",
    "        processes = []\n",
    "        list_task_drop = []\n",
    "        \n",
    "        # start processes on available cores\n",
    "        for i in range(min(n_cores, len(list_task))):\n",
    "            \n",
    "            # get the row index to work with\n",
    "            ind = list_task[i]\n",
    "            list_task_drop.append(ind)\n",
    "            \n",
    "            p = mp.Process(\n",
    "                target = cm.log_sum_binomial_sync,\n",
    "                args = (int(df_random_n[\"random_n\"].iloc[ind]), int(df_random_n[\"random_n_id\"].iloc[ind]), return_dict)\n",
    "            )\n",
    "            \n",
    "            processes.append(p)\n",
    "            p.start()\n",
    "            \n",
    "        # loop to close and join after starting\n",
    "        for p in processes:\n",
    "            p.join()\n",
    "\n",
    "        # update the return values\n",
    "        return_values.update(return_dict)\n",
    "        \n",
    "        # reduce the task list\n",
    "        list_task = [x for x in list_task if x not in list_task_drop]\n",
    "\n",
    "    t1_par_sync = time.time()\n",
    "\n",
    "    # \n",
    "    t_elapse_par_sync = t1_par_sync - t0_par_sync\n",
    "\n",
    "\n",
    "# print the reduction in time\n",
    "print(\"Synchronous parallelization across %s cores reduced computational time by %s%s.\"%(n_cores, round(100*(1 - t_elapse_par_sync/t_elapse_serial), 2), \"%\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95.40652322769165"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_elapse_serial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.08370804786682"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_elapse_par_async"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.233006238937378"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_elapse_par_sync"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
